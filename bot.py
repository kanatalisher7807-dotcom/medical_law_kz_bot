import os
import json
import re
import logging
import asyncio
from difflib import SequenceMatcher
from typing import Optional, Dict, Any, List, Tuple

from aiogram import Bot, Dispatcher, types
from aiogram.utils import executor
from aiogram.types import ReplyKeyboardMarkup, KeyboardButton

# OpenAI (fallback brain)
try:
    from openai import OpenAI
except Exception:
    OpenAI = None  # –µ—Å–ª–∏ –ø–∞–∫–µ—Ç –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω

logging.basicConfig(level=logging.INFO)

TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")  # –¥–æ–±–∞–≤–∏–º –≤ Render –ø–æ–∑–∂–µ

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# --- OpenAI client ---
oa_client = OpenAI(api_key=OPENAI_API_KEY) if (OpenAI and OPENAI_API_KEY) else None

AI_SYSTEM_PROMPT = """
–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∫–∞—Ñ–µ–¥—Ä—ã –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –ø—Ä–∞–≤–∞ –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω.

–û—Ç–≤–µ—á–∞–π:
‚Ä¢ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ-–¥–µ–ª–æ–≤—ã–º —Å—Ç–∏–ª–µ–º;
‚Ä¢ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ, –±–µ–∑ –æ—Ü–µ–Ω–æ–∫ –∏ —ç–º–æ—Ü–∏–π;
‚Ä¢ —Å —É—á—ë—Ç–æ–º –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω;
‚Ä¢ –∫—Ä–∞—Ç–∫–æ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–æ.

–ê–ª–≥–æ—Ä–∏—Ç–º –æ—Ç–≤–µ—Ç–∞:
1) –ö—Ä–∞—Ç–∫–æ –æ–±—ä—è—Å–Ω–∏ —Å—É—Ç—å —Å–∏—Ç—É–∞—Ü–∏–∏ (1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è).
2) –£–∫–∞–∂–∏, –∫ –∫–∞–∫–æ–º—É —Ä–∞–∑–¥–µ–ª—É –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –ø—Ä–∞–≤–∞ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –≤–æ–ø—Ä–æ—Å.
3) –î–∞–π –æ–±—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –¥–µ–π—Å—Ç–≤–∏–π (–ø—É–Ω–∫—Ç—ã).
4) –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —É–ø–æ–º—è–Ω–∏ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –∞–∫—Ç—ã (–±–µ–∑ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç–∞—Ç–µ–π).

–ù–ï –¥–∞–≤–∞–π –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö —Å–æ–≤–µ—Ç–æ–≤ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—á–Ω—ã—Ö –≤—ã–≤–æ–¥–æ–≤.

–í—Å–µ–≥–¥–∞ –∑–∞–≤–µ—Ä—à–∞–π –æ—Ç–≤–µ—Ç –¥–∏—Å–∫–ª–µ–π–º–µ—Ä–æ–º:
¬´–û—Ç–≤–µ—Ç –Ω–æ—Å–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä –∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–º —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–º –∑–∞–∫–ª—é—á–µ–Ω–∏–µ–º. –î–ª—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫—É ‚Äú–ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—é‚Äù.¬ª
"""

DISCLAIMER = (
    "‚ö†Ô∏è –û—Ç–≤–µ—Ç –Ω–æ—Å–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä –∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–º —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–º –∑–∞–∫–ª—é—á–µ–Ω–∏–µ–º. "
    "–î–ª—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫—É ¬´‚úâÔ∏è –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—é¬ª."

   )
AI_SYSTEM_PROMPT = """
–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∫–∞—Ñ–µ–¥—Ä—ã –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –ø—Ä–∞–≤–∞ –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω.

–û—Ç–≤–µ—á–∞–π:
‚Ä¢ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ-–¥–µ–ª–æ–≤—ã–º —Å—Ç–∏–ª–µ–º;
‚Ä¢ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ, –±–µ–∑ –æ—Ü–µ–Ω–æ–∫ –∏ —ç–º–æ—Ü–∏–π;
‚Ä¢ —Å —É—á—ë—Ç–æ–º –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω;
‚Ä¢ –∫—Ä–∞—Ç–∫–æ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–æ.

–ê–ª–≥–æ—Ä–∏—Ç–º –æ—Ç–≤–µ—Ç–∞:
1) –ö—Ä–∞—Ç–∫–æ –æ–±—ä—è—Å–Ω–∏ —Å—É—Ç—å —Å–∏—Ç—É–∞—Ü–∏–∏ (1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è).
2) –£–∫–∞–∂–∏, –∫ –∫–∞–∫–æ–º—É —Ä–∞–∑–¥–µ–ª—É –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –ø—Ä–∞–≤–∞ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –≤–æ–ø—Ä–æ—Å.
3) –î–∞–π –æ–±—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –¥–µ–π—Å—Ç–≤–∏–π (–ø—É–Ω–∫—Ç—ã).
4) –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —É–ø–æ–º—è–Ω–∏ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –∞–∫—Ç—ã (–±–µ–∑ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç–∞—Ç–µ–π).

–ù–ï –¥–∞–≤–∞–π –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö —Å–æ–≤–µ—Ç–æ–≤ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—á–Ω—ã—Ö –≤—ã–≤–æ–¥–æ–≤.

–í—Å–µ–≥–¥–∞ –∑–∞–≤–µ—Ä—à–∞–π –æ—Ç–≤–µ—Ç –¥–∏—Å–∫–ª–µ–π–º–µ—Ä–æ–º:
¬´–û—Ç–≤–µ—Ç –Ω–æ—Å–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä –∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–º —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–º –∑–∞–∫–ª—é—á–µ–Ω–∏–µ–º. –î–ª—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫—É ‚Äú–ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—é‚Äù.¬ª
"""
SECTIONS = [
    "‚öñÔ∏è –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –æ—à–∏–±–∫–∏",
    "üö® –ò–Ω—Ü–∏–¥–µ–Ω—Ç—ã",
    "üè• –ñ–∞–ª–æ–±—ã –ø–∞—Ü–∏–µ–Ω—Ç–∞",
    "‚úçÔ∏è –ò–Ω—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–≥–ª–∞—Å–∏–µ",
    "üîí –í—Ä–∞—á–µ–±–Ω–∞—è —Ç–∞–π–Ω–∞",
    "üëÆ –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –º–µ–¥—Ä–∞–±–æ—Ç–Ω–∏–∫–æ–≤",
    "üìÑ –ù–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞",
    "‚úâÔ∏è –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—é",
    "üß™ –ú–∏–Ω–∏-—Ç–µ—Å—Ç—ã",
]

# ---------- UI ----------
menu = ReplyKeyboardMarkup(resize_keyboard=True)
menu.add(KeyboardButton(SECTIONS[0]), KeyboardButton(SECTIONS[1]))
menu.add(KeyboardButton(SECTIONS[2]), KeyboardButton(SECTIONS[3]))
menu.add(KeyboardButton(SECTIONS[4]), KeyboardButton(SECTIONS[5]))
menu.add(KeyboardButton(SECTIONS[6]))
menu.add(KeyboardButton(SECTIONS[7]), KeyboardButton(SECTIONS[8]))

# ---------- Modes ----------
USER_MODE: Dict[int, str] = {}  # "exam" or ""
# --- PRO –¥–æ—Å—Ç—É–ø –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ (v1) ---
PRO_USERS = {
    # —Å—é–¥–∞ –¥–æ–±–∞–≤–ª—è–π Telegram ID —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ —Å PRO-–¥–æ—Å—Ç—É–ø–æ–º
    # –ø—Ä–∏–º–µ—Ä: 123456789,
}

DEMO_EXAM_LIMIT = 5  # —Å–∫–æ–ª—å–∫–æ —ç–∫–∑–∞–º–µ–Ω-–∫–∞—Ä—Ç–æ—á–µ–∫ –¥–æ—Å—Ç—É–ø–Ω–æ –≤ –¥–µ–º–æ
DEMO_EXAM_COUNTER: Dict[int, int] = {}  # —Å–∫–æ–ª—å–∫–æ –∫–∞—Ä—Ç–æ—á–µ–∫ —É–∂–µ –≤—ã–¥–∞–Ω–æ –∫–∞–∂–¥–æ–º—É

# ---------- Paths ----------
def resolve_path(env_var: str, filename: str) -> str:
    env_path = os.getenv(env_var)
    if env_path and os.path.exists(env_path):
        return env_path

    p1 = os.path.join(BASE_DIR, filename)
    if os.path.exists(p1):
        return p1

    p2 = os.path.join(os.getcwd(), filename)
    if os.path.exists(p2):
        return p2

    p3 = os.path.join(os.getcwd(), "medical_law_kz_bot", filename)
    if os.path.exists(p3):
        return p3

    return p1  # —Å–∞–º—ã–π –≤–µ—Ä–æ—è—Ç–Ω—ã–π

FAQ_PATH = resolve_path("FAQ_PATH", "faq.json")
EXAM_PATH = resolve_path("EXAM_PATH", "exam.json")

def load_json_list(path: str, label: str) -> List[Dict[str, Any]]:
    try:
        logging.info(f"Loading {label} from: {path} (exists={os.path.exists(path)})")
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
        if not isinstance(data, list):
            logging.warning(f"{label} is not a list -> empty.")
            return []
        logging.info(f"{label} loaded: {len(data)} entries")
        return data
    except Exception as e:
        logging.exception(f"Failed to load {label}: %s", e)
        return []

FAQ = load_json_list(FAQ_PATH, "FAQ")
EXAM = load_json_list(EXAM_PATH, "EXAM")

# ---------- Normalization / fuzzy ----------
_WORD_RE = re.compile(r"[a-z–∞-—è0-9]+", re.IGNORECASE)

ALIASES = {
    # —Ç–≤–æ–∏ —á–∞—Å—Ç—ã–µ "–æ–±—Ä—É–±–∫–∏/–æ–ø–µ—á–∞—Ç–∫–∏"
    "–∂–ª–±–∞": "–∂–∞–ª–æ–±–∞",
    "–∂–ª–±": "–∂–∞–ª–æ–±–∞",
    "–∂–±–∞": "–∂–∞–ª–æ–±–∞",
    "–∂–∞–ª–æ–±": "–∂–∞–ª–æ–±–∞",
    "—Ö–∞–º": "–≥—Ä—É–±–æ—Å—Ç—å",
    "—Ö–∞–º–∏—Ç": "–≥—Ä—É–±–æ—Å—Ç—å",
    "–≥—Ä—É–±–∏—Ç": "–≥—Ä—É–±–æ—Å—Ç—å",
    "–∫–æ–Ω—Ñ–ª": "–∫–æ–Ω—Ñ–ª–∏–∫—Ç",
    "—Å–∫–∞–Ω–¥–∞–ª": "–∫–æ–Ω—Ñ–ª–∏–∫—Ç",
    "–¥–∏–∞–≥–Ω": "–¥–∏–∞–≥–Ω–æ–∑",
    "–¥–∏–∞–≥": "–¥–∏–∞–≥–Ω–æ–∑",
    "—Ç–∞–π–Ω–∞": "–≤—Ä–∞—á–µ–±–Ω–∞—è —Ç–∞–π–Ω–∞",
    "—Å–æ–≥–ª–∞—Å–∏–µ": "–∏–Ω—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–≥–ª–∞—Å–∏–µ",
    "–æ—à–∏–±–∫–∞": "–º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –æ—à–∏–±–∫–∞",
    "–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å": "–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –º–µ–¥—Ä–∞–±–æ—Ç–Ω–∏–∫–æ–≤",
}

STOP_WORDS = {"–∏", "–≤", "–≤–æ", "–Ω–∞", "–ø–æ", "–∑–∞", "–∫", "–∫–æ", "–æ", "–æ–±", "–æ—Ç", "—ç—Ç–æ", "—á—Ç–æ", "–∫–∞–∫", "–ª–∏"}

def clean_text(s: str) -> str:
    s = (s or "").lower().replace("—ë", "–µ").strip()
    s = re.sub(r"[^0-9a-z–∞-—è\s-]+", " ", s, flags=re.IGNORECASE)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def normalize_query(s: str) -> str:
    s = clean_text(s)
    if s in ALIASES:
        s = ALIASES[s]
    return s

def tokens(s: str) -> List[str]:
    s = normalize_query(s)
    tks = _WORD_RE.findall(s)
    return [t for t in tks if t and t not in STOP_WORDS]

def sim(a: str, b: str) -> float:
    return SequenceMatcher(None, a, b).ratio()

def score_entry(entry: Dict[str, Any], user_text: str, keyword_field: str = "keywords") -> float:
    """
    –ë–∞–ª–ª—ã:
      +3.0 –µ—Å–ª–∏ keyword (—Ñ—Ä–∞–∑–∞) –≤—Ö–æ–¥–∏—Ç –≤ —Ç–µ–∫—Å—Ç
      +1.6 –µ—Å–ª–∏ –ø–æ—Ö–æ–∂–µ—Å—Ç—å —Ç–æ–∫–µ–Ω–∞ >= 0.78
      +1.1 –µ—Å–ª–∏ –æ–±—Ä—É–±–æ–∫ –≤—Ö–æ–¥–∏—Ç (tk in kw or kw in tk) –ø—Ä–∏ –¥–ª–∏–Ω–µ >= 4
    """
    text = normalize_query(user_text)
    tks = tokens(text)
    kws = entry.get(keyword_field) or []
    if not isinstance(kws, list):
        return 0.0

    total = 0.0
    for kw in kws:
        if not isinstance(kw, str) or not kw.strip():
            continue
        kw_n = normalize_query(kw)

        if kw_n and kw_n in text:
            total += 3.0
            continue

        # fuzzy –ø–æ —Å–ª–æ–≤–∞–º
        best_local = 0.0
        for tk in tks:
            if not tk or not kw_n:
                continue
            r = sim(tk, kw_n)
            if r > best_local:
                best_local = r
            # –æ–±—Ä—É–±–∫–∏
            if len(tk) >= 4 and len(kw_n) >= 4 and (tk in kw_n or kw_n in tk):
                best_local = max(best_local, 0.80)

        if best_local >= 0.78:
            total += 1.6
        elif best_local >= 0.70:
            total += 0.9

    # –º–∞–ª–µ–Ω—å–∫–∏–π –±–æ–Ω—É—Å, –µ—Å–ª–∏ —ç—Ç–æ "card" (—á—Ç–æ–±—ã –æ—Ç–≤–µ—Ç—ã —á–∞—â–µ –Ω–∞—Ö–æ–¥–∏–ª–∏—Å—å)
    if entry.get("type") in ("card", "answer"):
        total += 0.1

    return total

def best_match(entries: List[Dict[str, Any]], user_text: str, keyword_field: str = "keywords") -> Tuple[Optional[Dict[str, Any]], float]:
    best = None
    best_score = 0.0
    for e in entries:
        sc = score_entry(e, user_text, keyword_field=keyword_field)
        if sc > best_score:
            best_score = sc
            best = e
    return best, best_score

# ---------- Formatters ----------
def format_faq(entry: Dict[str, Any]) -> str:
    answer = (entry.get("answer") or entry.get("a") or "").strip()
    law = (entry.get("law") or "").strip()
    if law:
        answer += f"\n\nüî∑ –ù–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞: {law}"
    answer += f"\n\n{DISCLAIMER}"
    return answer

def format_exam(entry: Dict[str, Any]) -> str:
    q = (entry.get("question") or "").strip()
    ideal = (entry.get("ideal_answer") or "").strip()
    comment = (entry.get("comment") or "").strip()
    mistake = (entry.get("common_mistake") or "").strip()
    law = (entry.get("law") or "").strip()

    out = "üéì –≠–∫–∑–∞–º–µ–Ω–∞—Ü–∏–æ–Ω–Ω–∞—è –∫–∞—Ä—Ç–æ—á–∫–∞"
    if q:
        out += f"\n\nüìå –í–æ–ø—Ä–æ—Å:\n{q}"
    if ideal:
        out += f"\n\n‚úÖ –≠—Ç–∞–ª–æ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç:\n{ideal}"
    if comment:
        out += f"\n\nüí° –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π:\n{comment}"
    if mistake:
        out += f"\n\n‚ö†Ô∏è –¢–∏–ø–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞:\n{mistake}"
    if law:
        out += f"\n\nüî∑ –ù–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞:\n{law}"
    out += f"\n\n{DISCLAIMER}"
    return out

def find_intro(section_key: str) -> Optional[Dict[str, Any]]:
    return next((e for e in FAQ if e.get("section") == section_key and e.get("type") == "intro"), None)

def find_definition(section_key: str) -> Optional[Dict[str, Any]]:
    # –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞: type="def" –∏–ª–∏ role="lead"
    lead = next((e for e in FAQ if e.get("section") == section_key and e.get("type") in ("def",) ), None)
    if lead:
        return lead
    lead2 = next((e for e in FAQ if e.get("section") == section_key and e.get("type") in ("card", "answer") and e.get("role") == "lead"), None)
    return lead2

# ---------- OpenAI fallback ----------
client = OpenAI(api_key=OPENAI_API_KEY) if (OpenAI and OPENAI_API_KEY) else None

def _openai_sync_answer(user_text: str) -> Optional[str]:
    if not client:
        return None

    system_rules = (
        "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –∫–∞—Ñ–µ–¥—Ä—ã –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –ø—Ä–∞–≤–∞ (–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω). "
        "–°—Ç–∏–ª—å: –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ-–¥–µ–ª–æ–≤–æ–π, –∫—Ä–∞—Ç–∫–æ, –ø–æ —à–∞–≥–∞–º. "
        "–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–æ–º–µ—Ä–∞ —Å—Ç–∞—Ç–µ–π/–ø—Ä–∏–∫–∞–∑–æ–≤ –∏ —Ç–æ—á–Ω—ã–µ —Ä–µ–∫–≤–∏–∑–∏—Ç—ã, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç. "
        "–ï—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è —É—Ç–æ—á–Ω–µ–Ω–∏–µ ‚Äî –∑–∞–¥–∞–π 2-3 –∫–æ—Ä–æ—Ç–∫–∏—Ö —É—Ç–æ—á–Ω—è—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–∞. "
        "–í –∫–æ–Ω—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–∏ –∫–Ω–æ–ø–∫—É ¬´‚úâÔ∏è –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—é¬ª –¥–ª—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ –∫–µ–π—Å–∞."
    )

    # Responses API (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π)
    resp = client.responses.create(
        model="gpt-4o-mini",
        input=[
            {"role": "system", "content": system_rules},
            {"role": "user", "content": user_text},
        ],
        # store –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω; –æ—Å—Ç–∞–≤–ª—è–µ–º false-–ª–æ–≥–∏–∫–æ–π (–±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
        store=False,
    )
    return (resp.output_text or "").strip() or None

async def openai_answer(user_text: str, timeout_s: int = 18) -> Optional[str]:
    if not client:
        return None
    loop = asyncio.get_event_loop()
    try:
        return await asyncio.wait_for(loop.run_in_executor(None, _openai_sync_answer, user_text), timeout=timeout_s)
    except Exception as e:
        logging.warning(f"OpenAI fallback failed: {e}")
        return None
async def ask_ai(user_text: str) -> str:
    """Fallback-–æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ OpenAI, –∫–æ–≥–¥–∞ FAQ –Ω–µ –Ω–∞—à—ë–ª."""
    if not oa_client:
        return (
            "AI —Å–µ–π—á–∞—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.\n"
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ ¬´‚úâÔ∏è –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—é¬ª."
        )

    def _call() -> str:
        resp = oa_client.responses.create(
            model="gpt-5-mini",
            input=[
                {"role": "system", "content": AI_SYSTEM_PROMPT},
                {"role": "user", "content": user_text},
            ],
        )
        return (getattr(resp, "output_text", "") or "").strip()

    try:
        text = await asyncio.to_thread(_call)
        if not text:
            return (
                "–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç.\n"
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –Ω–∞–ø–∏—Å–∞—Ç—å –ø—Ä–æ—â–µ (1‚Äì2 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞) "
                "–∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ ¬´‚úâÔ∏è –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—é¬ª."
            )
        return text
    except Exception as e:
        logging.exception("OpenAI error: %s", e)
        return (
            "AI –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.\n"
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ ¬´‚úâÔ∏è –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—é¬ª."
        )

# ---------- Aiogram ----------
if not TOKEN:
    raise RuntimeError("TELEGRAM_TOKEN is not set.")

bot = Bot(token=TOKEN)
dp = Dispatcher(bot)

@dp.message_handler(commands=["start"])
async def start(message: types.Message):
    text = (
        "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –Ø –±–æ—Ç –∫–∞—Ñ–µ–¥—Ä—ã –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –ø—Ä–∞–≤–∞.\n\n"
        "–Ø –ø–æ–º–æ–≥–∞—é —Å —Ç–∏–ø–æ–≤—ã–º–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏: –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –æ—à–∏–±–∫–∏, –∏–Ω—Ü–∏–¥–µ–Ω—Ç—ã, –∂–∞–ª–æ–±—ã, "
        "–∏–Ω—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–≥–ª–∞—Å–∏–µ, –≤—Ä–∞—á–µ–±–Ω–∞—è —Ç–∞–π–Ω–∞, –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å.\n\n"
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–¥–µ–ª –∫–Ω–æ–ø–∫–∞–º–∏ –Ω–∏–∂–µ –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ –≤–æ–ø—Ä–æ—Å —Ç–µ–∫—Å—Ç–æ–º."
    )
    await message.answer(text, reply_markup=menu)

@dp.message_handler(commands=["help", "menu"])
async def help_cmd(message: types.Message):
    await message.answer("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–¥–µ–ª –∫–Ω–æ–ø–∫–∞–º–∏ –∏–ª–∏ –Ω–∞–ø–∏—à–∏—Ç–µ –≤–æ–ø—Ä–æ—Å —Ç–µ–∫—Å—Ç–æ–º.", reply_markup=menu)

@dp.message_handler(lambda m: (m.text or "").strip() == "üìÑ –ù–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞")
async def law_base(message: types.Message):
    text = (
        "üìÑ –ù–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞ (–æ—Ä–∏–µ–Ω—Ç–∏—Ä—ã):\n"
        "‚Ä¢ –ö–æ–¥–µ–∫—Å –†–ö ¬´–û –∑–¥–æ—Ä–æ–≤—å–µ –Ω–∞—Ä–æ–¥–∞ –∏ —Å–∏—Å—Ç–µ–º–µ –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è¬ª\n"
        "‚Ä¢ –£–ö / –ö–æ–ê–ü / –ì–ö / –¢–ö –†–ö ‚Äî –ø–æ —Å–∏—Ç—É–∞—Ü–∏–∏\n"
        "‚Ä¢ –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Ä–µ–≥–ª–∞–º–µ–Ω—Ç—ã –º–µ–¥–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏ –ø—Ä–∏–∫–∞–∑—ã —É–ø–æ–ª–Ω–æ–º–æ—á–µ–Ω–Ω–æ–≥–æ –æ—Ä–≥–∞–Ω–∞\n\n"
        "–ï—Å–ª–∏ –Ω–∞–ø–∏—à–µ—Ç–µ —Ç–µ–º—É (–Ω–∞–ø—Ä–∏–º–µ—Ä, ¬´–≤—Ä–∞—á–µ–±–Ω–∞—è —Ç–∞–π–Ω–∞¬ª), —è –ø–æ–¥—Å–∫–∞–∂—É —Ç–∏–ø–æ–≤–æ–π –±–ª–æ–∫ –Ω–æ—Ä–º."
    )
    await message.answer(text, reply_markup=menu)

@dp.message_handler(lambda m: (m.text or "").strip() == "‚úâÔ∏è –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—é")
async def ask_teacher(message: types.Message):
    await message.answer(
        "–ù–∞–ø–∏—à–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º.\n"
        "–§–æ—Ä–º–∞—Ç: *–¢–µ–º–∞* ‚Üí *–°—É—Ç—å –≤–æ–ø—Ä–æ—Å–∞*.\n"
        "–ù–µ —É–∫–∞–∑—ã–≤–∞–π—Ç–µ –ª–∏—à–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.",
        parse_mode="Markdown",
        reply_markup=menu,
    )

@dp.message_handler(lambda m: (m.text or "").strip() == "üß™ –ú–∏–Ω–∏-—Ç–µ—Å—Ç—ã")
async def mini_tests(message: types.Message):
    USER_MODE[message.from_user.id] = "exam"
    await message.answer(
        "üß™ –≠–∫–∑–∞–º–µ–Ω–∞—Ü–∏–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º –≤–∫–ª—é—á—ë–Ω.\n\n"
        "–ü–∏—à–∏—Ç–µ —Ç–µ–º—É/–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞. –ß—Ç–æ–±—ã –≤—ã–π—Ç–∏ ‚Äî –Ω–∞–ø–∏—à–∏—Ç–µ: –≤—ã—Ö–æ–¥",
        reply_markup=menu,
    )
@dp.message_handler(lambda m: (m.text or "").strip().lower() in {"—Ö–æ—á—É pro-–¥–æ—Å—Ç—É–ø", "—Ö–æ—á—É pro –¥–æ—Å—Ç—É–ø", "pro-–¥–æ—Å—Ç—É–ø", "pro –¥–æ—Å—Ç—É–ø"})
async def want_pro(message: types.Message):
    text = (
        "üîí –≠–∫–∑–∞–º–µ–Ω–∞—Ü–∏–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º PRO\n\n"
        "–ü–æ–ª–Ω—ã–π –¥–æ—Å—Ç—É–ø –≤–∫–ª—é—á–∞–µ—Ç:\n"
        "‚Ä¢ –≤–µ—Å—å –±–∞–Ω–∫ —ç–∫–∑–∞–º–µ–Ω–∞—Ü–∏–æ–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤;\n"
        "‚Ä¢ —ç—Ç–∞–ª–æ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –≤ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ-–¥–µ–ª–æ–≤–æ–º —Å—Ç–∏–ª–µ;\n"
        "‚Ä¢ —Ç–∏–ø–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤;\n"
        "‚Ä¢ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –æ—Ä–∏–µ–Ω—Ç–∏—Ä—ã –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏.\n\n"
        "–î–æ—Å—Ç—É–ø –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –æ–±—É—á–∞—é—â–∏–º—Å—è –∫–∞—Ñ–µ–¥—Ä—ã.\n"
        "–î–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –Ω–∞–ø–∏—à–∏—Ç–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É –∫–∞—Ñ–µ–¥—Ä—ã –∏–ª–∏ –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—é, –∫—É—Ä–∏—Ä—É—é—â–µ–º—É –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—É."
    )
    await message.answer(text, reply_markup=menu)

# –ö–Ω–æ–ø–∫–∞ —Ä–∞–∑–¥–µ–ª–∞: intro + def (–µ—Å–ª–∏ –µ—Å—Ç—å)
@dp.message_handler(lambda m: (m.text or "").strip() in SECTIONS)
async def handle_section_buttons(message: types.Message):
    key = (message.text or "").strip()

    # –¥–ª—è —Ç—Ä—ë—Ö —Å–ø–µ—Ü-–∫–Ω–æ–ø–æ–∫ —É–∂–µ –µ—Å—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ö—ç–Ω–¥–ª–µ—Ä—ã –≤—ã—à–µ
    if key in ("üìÑ –ù–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞", "‚úâÔ∏è –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—é", "üß™ –ú–∏–Ω–∏-—Ç–µ—Å—Ç—ã"):
        return

    intro = find_intro(key)
    definition = find_definition(key)

    parts = []
    if intro:
        parts.append((intro.get("answer") or "").strip())
    if definition and definition is not intro:
        parts.append((definition.get("answer") or "").strip())

    if parts:
        out = "\n\n".join([p for p in parts if p])
        out += f"\n\n{DISCLAIMER}"
        await message.answer(out, reply_markup=menu)
        return

    await message.answer(
        "–†–∞–∑–¥–µ–ª –æ—Ç–∫—Ä—ã—Ç. –ù–∞–ø–∏—à–∏—Ç–µ 1‚Äì2 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞ –ø–æ —Ç–µ–º–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä: ¬´–∂–∞–ª–æ–±–∞¬ª, ¬´–æ—Ç–∫–∞–∑–∞–ª–∏¬ª, ¬´—Ç–∞–π–Ω–∞¬ª).",
        reply_markup=menu
    )

# –ï–î–ò–ù–°–¢–í–ï–ù–ù–´–ô —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ö—ç–Ω–¥–ª–µ—Ä (—á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ —Ç–∏—à–∏–Ω—ã/–∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤)
@dp.message_handler(lambda m: m.text and (not m.text.startswith("/")) and ((m.text or "").strip() not in SECTIONS))
async def handle_text(message: types.Message):
    uid = message.from_user.id
    raw = (message.text or "").strip()
    # 0) –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è ‚Äî –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ–º –Ω–∏ FAQ, –Ω–∏ EXAM, –Ω–∏ AI
    greetings = {"–ø—Ä–∏–≤–µ—Ç", "–ø—Ä–∏–≤", "hello", "hi", "–∑–¥–∞—Ä–æ–≤–∞", "–∑–¥—Ä–∞—Å—å—Ç–µ", "–∫—É", "—Å–∞–ª–∞–º", "—Å–∞–ª–µ–º", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ"}
    norm = raw.lower().strip(" .,!?:;")
    if norm in greetings:
        await message.answer(
            "–ü—Ä–∏–≤–µ—Ç! üôÇ\n\n"
            "–ú–æ–∂–µ—à—å:\n"
            "‚Ä¢ –Ω–∞–∂–∞—Ç—å –∫–Ω–æ–ø–∫—É –Ω—É–∂–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞ –Ω–∏–∂–µ,\n"
            "‚Ä¢ –∏–ª–∏ –Ω–∞–ø–∏—Å–∞—Ç—å –≤–æ–ø—Ä–æ—Å 1‚Äì2 —Å–ª–æ–≤–∞–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä: ¬´–∂–∞–ª–æ–±–∞¬ª, ¬´—Ö–∞–º—Å—Ç–≤–æ –≤—Ä–∞—á–∞¬ª, ¬´–æ—Ç–∫–∞–∑ –≤ –ø–æ–º–æ—â–∏¬ª).",
            reply_markup=menu
        )
        return

    # –≤—ã—Ö–æ–¥ –∏–∑ —ç–∫–∑–∞–º–µ–Ω-—Ä–µ–∂–∏–º–∞
    if USER_MODE.get(uid) == "exam" and raw.lower() in ("–≤—ã—Ö–æ–¥", "–≤—ã–π—Ç–∏", "exit"):
        USER_MODE.pop(uid, None)
        await message.answer("–≠–∫–∑–∞–º–µ–Ω–∞—Ü–∏–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º –≤—ã–∫–ª—é—á—ë–Ω. –ú–æ–∂–µ—Ç–µ –∑–∞–¥–∞–≤–∞—Ç—å –æ–±—ã—á–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã.", reply_markup=menu)
        return

    # 1) –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω exam-—Ä–µ–∂–∏–º ‚Äî —Å–Ω–∞—á–∞–ª–∞ EXAM
    if USER_MODE.get(uid) == "exam":
                # –î–ï–ú–û-–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ: –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ PRO ‚Äî –¥–∞—ë–º —Ç–æ–ª—å–∫–æ DEMO_EXAM_LIMIT –∫–∞—Ä—Ç–æ—á–µ–∫
        if uid not in PRO_USERS:
            used = DEMO_EXAM_COUNTER.get(uid, 0)
            if used >= DEMO_EXAM_LIMIT:
                await message.answer(
                    "üîí –≠–∫–∑–∞–º–µ–Ω–∞—Ü–∏–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º (–¥–µ–º–æ)\n\n"
                    "–î–æ—Å—Ç—É–ø–Ω—ã–π –ª–∏–º–∏—Ç –∫–∞—Ä—Ç–æ—á–µ–∫ –≤ –¥–µ–º–æ –∏—Å—á–µ—Ä–ø–∞–Ω.\n"
                    "–ß—Ç–æ–±—ã –ø–æ–¥–∫–ª—é—á–∏—Ç—å –ø–æ–ª–Ω—ã–π –¥–æ—Å—Ç—É–ø, –Ω–∞–ø–∏—à–∏—Ç–µ: ¬´–•–æ—á—É PRO-–¥–æ—Å—Ç—É–ø¬ª.",
                    reply_markup=menu,
                )
                return
        exam_entry, exam_score = best_match(EXAM, raw, keyword_field="keywords")
        if exam_entry and exam_score >= 1.0:
                        if uid not in PRO_USERS:
                DEMO_EXAM_COUNTER[uid] = DEMO_EXAM_COUNTER.get(uid, 0) + 1
        await message.answer(format_exam(exam_entry), reply_markup=menu)
            return
        await message.answer(
            "–ü–æ —ç—Ç–æ–º—É –∑–∞–ø—Ä–æ—Å—É —ç–∫–∑–∞–º–µ–Ω–∞—Ü–∏–æ–Ω–Ω–∞—è –∫–∞—Ä—Ç–æ—á–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.\n"
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø—Ä–æ—â–µ: ¬´–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å¬ª, ¬´–¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞—Ä–Ω–∞—è¬ª, ¬´—É–≥–æ–ª–æ–≤–Ω–∞—è¬ª.",
            reply_markup=menu,
        )
        return

    # 2) –æ–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º: –∏—â–µ–º —Ç–æ–ª—å–∫–æ –ø–æ FAQ
    faq_entry, faq_score = best_match(FAQ, raw, keyword_field="keywords")
    faq_ok = faq_entry is not None and faq_score >= 1.2  # –ø–æ—Ä–æ–≥ –ø–æ–≤—ã—à–µ, —á—Ç–æ–±—ã "–º—É—Å–æ—Ä" –Ω–µ –ª–æ–≤–∏—Ç—å

    if faq_ok:
        section = (faq_entry.get("section") or "").strip()
        definition = find_definition(section) if section else None

        parts = []
        if definition and definition is not faq_entry:
            parts.append((definition.get("answer") or "").strip())

        parts.append((faq_entry.get("answer") or faq_entry.get("a") or "").strip())

        out = "\n\n".join([p for p in parts if p])
        law = (faq_entry.get("law") or "").strip()
        if law:
            out += f"\n\nüî∑ –ù–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞: {law}"
        out += f"\n\n{DISCLAIMER}"

        await message.answer(out, reply_markup=menu)
        return


    # 3) –µ—Å–ª–∏ –±–∞–∑—ã –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –ø–æ–¥–∫–ª—é—á–∞–µ–º –º–µ–Ω—è (AI-fallback), –µ—Å–ª–∏ –∫–ª—é—á –∑–∞–¥–∞–Ω
    ai_text = await openai_answer(raw)
    if ai_text:
        out = ai_text.strip() + f"\n\n{DISCLAIMER}"
        await message.answer(out, reply_markup=menu)
        return

    # 4) —Å–æ–≤—Å–µ–º –Ω–∏—á–µ–≥–æ
    await message.answer(
        "–ù–µ –Ω–∞—à—ë–ª —Ç–æ—á–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.\n"
        "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø—Ä–æ—â–µ (1‚Äì2 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞) "
        "–∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ ¬´‚úâÔ∏è –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—é¬ª.",
        reply_markup=menu,
    )
    return
    
if __name__ == "__main__":
    executor.start_polling(dp, skip_updates=True)

