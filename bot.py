import os
import json
import re
import logging
import asyncio
from difflib import SequenceMatcher
from typing import Optional, Dict, Any, List, Tuple

from aiogram import Bot, Dispatcher, types
from aiogram.utils import executor
from aiogram.types import ReplyKeyboardMarkup, KeyboardButton

# OpenAI (fallback brain)
try:
    from openai import OpenAI
except Exception:
    OpenAI = None  # –µ—Å–ª–∏ –ø–∞–∫–µ—Ç –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω

logging.basicConfig(level=logging.INFO)

TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")  # –¥–æ–±–∞–≤–∏–º –≤ Render –ø–æ–∑–∂–µ

BASE_DIR = os.path.dirname(os.path.abspath(__file__))

DISCLAIMER = (
    "‚ö†Ô∏è –û—Ç–≤–µ—Ç –Ω–æ—Å–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä –∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–º —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–º –∑–∞–∫–ª—é—á–µ–Ω–∏–µ–º. "
    "–î–ª—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫—É ¬´‚úâÔ∏è –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—é¬ª."

   )
 AI_SYSTEM_PROMPT = """
–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∫–∞—Ñ–µ–¥—Ä—ã –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –ø—Ä–∞–≤–∞ –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω.

–û—Ç–≤–µ—á–∞–π:
‚Ä¢ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ-–¥–µ–ª–æ–≤—ã–º —Å—Ç–∏–ª–µ–º;
‚Ä¢ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ, –±–µ–∑ –æ—Ü–µ–Ω–æ–∫ –∏ —ç–º–æ—Ü–∏–π;
‚Ä¢ —Å —É—á—ë—Ç–æ–º –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω;
‚Ä¢ –∫—Ä–∞—Ç–∫–æ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–æ.

–ê–ª–≥–æ—Ä–∏—Ç–º –æ—Ç–≤–µ—Ç–∞:
1) –ö—Ä–∞—Ç–∫–æ –æ–±—ä—è—Å–Ω–∏ —Å—É—Ç—å —Å–∏—Ç—É–∞—Ü–∏–∏ (1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è).
2) –£–∫–∞–∂–∏, –∫ –∫–∞–∫–æ–º—É —Ä–∞–∑–¥–µ–ª—É –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –ø—Ä–∞–≤–∞ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –≤–æ–ø—Ä–æ—Å.
3) –î–∞–π –æ–±—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –¥–µ–π—Å—Ç–≤–∏–π (–ø—É–Ω–∫—Ç—ã).
4) –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —É–ø–æ–º—è–Ω–∏ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –∞–∫—Ç—ã (–±–µ–∑ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç–∞—Ç–µ–π).

–ù–ï –¥–∞–≤–∞–π –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö —Å–æ–≤–µ—Ç–æ–≤ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—á–Ω—ã—Ö –≤—ã–≤–æ–¥–æ–≤.

–í—Å–µ–≥–¥–∞ –∑–∞–≤–µ—Ä—à–∞–π –æ—Ç–≤–µ—Ç –¥–∏—Å–∫–ª–µ–π–º–µ—Ä–æ–º:
¬´–û—Ç–≤–µ—Ç –Ω–æ—Å–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä –∏ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–º —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–º –∑–∞–∫–ª—é—á–µ–Ω–∏–µ–º. –î–ª—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫—É ‚Äú–ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—é‚Äù.¬ª
"""
SECTIONS = [
    "‚öñÔ∏è –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –æ—à–∏–±–∫–∏",
    "üö® –ò–Ω—Ü–∏–¥–µ–Ω—Ç—ã",
    "üè• –ñ–∞–ª–æ–±—ã –ø–∞—Ü–∏–µ–Ω—Ç–∞",
    "‚úçÔ∏è –ò–Ω—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–≥–ª–∞—Å–∏–µ",
    "üîí –í—Ä–∞—á–µ–±–Ω–∞—è —Ç–∞–π–Ω–∞",
    "üëÆ –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –º–µ–¥—Ä–∞–±–æ—Ç–Ω–∏–∫–æ–≤",
    "üìÑ –ù–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞",
    "‚úâÔ∏è –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—é",
    "üß™ –ú–∏–Ω–∏-—Ç–µ—Å—Ç—ã",
]

# ---------- UI ----------
menu = ReplyKeyboardMarkup(resize_keyboard=True)
menu.add(KeyboardButton(SECTIONS[0]), KeyboardButton(SECTIONS[1]))
menu.add(KeyboardButton(SECTIONS[2]), KeyboardButton(SECTIONS[3]))
menu.add(KeyboardButton(SECTIONS[4]), KeyboardButton(SECTIONS[5]))
menu.add(KeyboardButton(SECTIONS[6]))
menu.add(KeyboardButton(SECTIONS[7]), KeyboardButton(SECTIONS[8]))

# ---------- Modes ----------
USER_MODE: Dict[int, str] = {}  # "exam" or ""

# ---------- Paths ----------
def resolve_path(env_var: str, filename: str) -> str:
    env_path = os.getenv(env_var)
    if env_path and os.path.exists(env_path):
        return env_path

    p1 = os.path.join(BASE_DIR, filename)
    if os.path.exists(p1):
        return p1

    p2 = os.path.join(os.getcwd(), filename)
    if os.path.exists(p2):
        return p2

    p3 = os.path.join(os.getcwd(), "medical_law_kz_bot", filename)
    if os.path.exists(p3):
        return p3

    return p1  # —Å–∞–º—ã–π –≤–µ—Ä–æ—è—Ç–Ω—ã–π

FAQ_PATH = resolve_path("FAQ_PATH", "faq.json")
EXAM_PATH = resolve_path("EXAM_PATH", "exam.json")

def load_json_list(path: str, label: str) -> List[Dict[str, Any]]:
    try:
        logging.info(f"Loading {label} from: {path} (exists={os.path.exists(path)})")
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
        if not isinstance(data, list):
            logging.warning(f"{label} is not a list -> empty.")
            return []
        logging.info(f"{label} loaded: {len(data)} entries")
        return data
    except Exception as e:
        logging.exception(f"Failed to load {label}: %s", e)
        return []

FAQ = load_json_list(FAQ_PATH, "FAQ")
EXAM = load_json_list(EXAM_PATH, "EXAM")

# ---------- Normalization / fuzzy ----------
_WORD_RE = re.compile(r"[a-z–∞-—è0-9]+", re.IGNORECASE)

ALIASES = {
    # —Ç–≤–æ–∏ —á–∞—Å—Ç—ã–µ "–æ–±—Ä—É–±–∫–∏/–æ–ø–µ—á–∞—Ç–∫–∏"
    "–∂–ª–±–∞": "–∂–∞–ª–æ–±–∞",
    "–∂–ª–±": "–∂–∞–ª–æ–±–∞",
    "–∂–±–∞": "–∂–∞–ª–æ–±–∞",
    "–∂–∞–ª–æ–±": "–∂–∞–ª–æ–±–∞",
    "—Ö–∞–º": "–≥—Ä—É–±–æ—Å—Ç—å",
    "—Ö–∞–º–∏—Ç": "–≥—Ä—É–±–æ—Å—Ç—å",
    "–≥—Ä—É–±–∏—Ç": "–≥—Ä—É–±–æ—Å—Ç—å",
    "–∫–æ–Ω—Ñ–ª": "–∫–æ–Ω—Ñ–ª–∏–∫—Ç",
    "—Å–∫–∞–Ω–¥–∞–ª": "–∫–æ–Ω—Ñ–ª–∏–∫—Ç",
    "–¥–∏–∞–≥–Ω": "–¥–∏–∞–≥–Ω–æ–∑",
    "–¥–∏–∞–≥": "–¥–∏–∞–≥–Ω–æ–∑",
    "—Ç–∞–π–Ω–∞": "–≤—Ä–∞—á–µ–±–Ω–∞—è —Ç–∞–π–Ω–∞",
    "—Å–æ–≥–ª–∞—Å–∏–µ": "–∏–Ω—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–≥–ª–∞—Å–∏–µ",
    "–æ—à–∏–±–∫–∞": "–º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –æ—à–∏–±–∫–∞",
    "–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å": "–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –º–µ–¥—Ä–∞–±–æ—Ç–Ω–∏–∫–æ–≤",
}

STOP_WORDS = {"–∏", "–≤", "–≤–æ", "–Ω–∞", "–ø–æ", "–∑–∞", "–∫", "–∫–æ", "–æ", "–æ–±", "–æ—Ç", "—ç—Ç–æ", "—á—Ç–æ", "–∫–∞–∫", "–ª–∏"}

def clean_text(s: str) -> str:
    s = (s or "").lower().replace("—ë", "–µ").strip()
    s = re.sub(r"[^0-9a-z–∞-—è\s-]+", " ", s, flags=re.IGNORECASE)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def normalize_query(s: str) -> str:
    s = clean_text(s)
    if s in ALIASES:
        s = ALIASES[s]
    return s

def tokens(s: str) -> List[str]:
    s = normalize_query(s)
    tks = _WORD_RE.findall(s)
    return [t for t in tks if t and t not in STOP_WORDS]

def sim(a: str, b: str) -> float:
    return SequenceMatcher(None, a, b).ratio()

def score_entry(entry: Dict[str, Any], user_text: str, keyword_field: str = "keywords") -> float:
    """
    –ë–∞–ª–ª—ã:
      +3.0 –µ—Å–ª–∏ keyword (—Ñ—Ä–∞–∑–∞) –≤—Ö–æ–¥–∏—Ç –≤ —Ç–µ–∫—Å—Ç
      +1.6 –µ—Å–ª–∏ –ø–æ—Ö–æ–∂–µ—Å—Ç—å —Ç–æ–∫–µ–Ω–∞ >= 0.78
      +1.1 –µ—Å–ª–∏ –æ–±—Ä—É–±–æ–∫ –≤—Ö–æ–¥–∏—Ç (tk in kw or kw in tk) –ø—Ä–∏ –¥–ª–∏–Ω–µ >= 4
    """
    text = normalize_query(user_text)
    tks = tokens(text)
    kws = entry.get(keyword_field) or []
    if not isinstance(kws, list):
        return 0.0

    total = 0.0
    for kw in kws:
        if not isinstance(kw, str) or not kw.strip():
            continue
        kw_n = normalize_query(kw)

        if kw_n and kw_n in text:
            total += 3.0
            continue

        # fuzzy –ø–æ —Å–ª–æ–≤–∞–º
        best_local = 0.0
        for tk in tks:
            if not tk or not kw_n:
                continue
            r = sim(tk, kw_n)
            if r > best_local:
                best_local = r
            # –æ–±—Ä—É–±–∫–∏
            if len(tk) >= 4 and len(kw_n) >= 4 and (tk in kw_n or kw_n in tk):
                best_local = max(best_local, 0.80)

        if best_local >= 0.78:
            total += 1.6
        elif best_local >= 0.70:
            total += 0.9

    # –º–∞–ª–µ–Ω—å–∫–∏–π –±–æ–Ω—É—Å, –µ—Å–ª–∏ —ç—Ç–æ "card" (—á—Ç–æ–±—ã –æ—Ç–≤–µ—Ç—ã —á–∞—â–µ –Ω–∞—Ö–æ–¥–∏–ª–∏—Å—å)
    if entry.get("type") in ("card", "answer"):
        total += 0.1

    return total

def best_match(entries: List[Dict[str, Any]], user_text: str, keyword_field: str = "keywords") -> Tuple[Optional[Dict[str, Any]], float]:
    best = None
    best_score = 0.0
    for e in entries:
        sc = score_entry(e, user_text, keyword_field=keyword_field)
        if sc > best_score:
            best_score = sc
            best = e
    return best, best_score

# ---------- Formatters ----------
def format_faq(entry: Dict[str, Any]) -> str:
    answer = (entry.get("answer") or entry.get("a") or "").strip()
    law = (entry.get("law") or "").strip()
    if law:
        answer += f"\n\nüî∑ –ù–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞: {law}"
    answer += f"\n\n{DISCLAIMER}"
    return answer

def format_exam(entry: Dict[str, Any]) -> str:
    q = (entry.get("question") or "").strip()
    ideal = (entry.get("ideal_answer") or "").strip()
    comment = (entry.get("comment") or "").strip()
    mistake = (entry.get("common_mistake") or "").strip()
    law = (entry.get("law") or "").strip()

    out = "üéì –≠–∫–∑–∞–º–µ–Ω–∞—Ü–∏–æ–Ω–Ω–∞—è –∫–∞—Ä—Ç–æ—á–∫–∞"
    if q:
        out += f"\n\nüìå –í–æ–ø—Ä–æ—Å:\n{q}"
    if ideal:
        out += f"\n\n‚úÖ –≠—Ç–∞–ª–æ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç:\n{ideal}"
    if comment:
        out += f"\n\nüí° –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π:\n{comment}"
    if mistake:
        out += f"\n\n‚ö†Ô∏è –¢–∏–ø–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞:\n{mistake}"
    if law:
        out += f"\n\nüî∑ –ù–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞:\n{law}"
    out += f"\n\n{DISCLAIMER}"
    return out

def find_intro(section_key: str) -> Optional[Dict[str, Any]]:
    return next((e for e in FAQ if e.get("section") == section_key and e.get("type") == "intro"), None)

def find_definition(section_key: str) -> Optional[Dict[str, Any]]:
    # –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞: type="def" –∏–ª–∏ role="lead"
    lead = next((e for e in FAQ if e.get("section") == section_key and e.get("type") in ("def",) ), None)
    if lead:
        return lead
    lead2 = next((e for e in FAQ if e.get("section") == section_key and e.get("type") in ("card", "answer") and e.get("role") == "lead"), None)
    return lead2

# ---------- OpenAI fallback ----------
client = OpenAI(api_key=OPENAI_API_KEY) if (OpenAI and OPENAI_API_KEY) else None

def _openai_sync_answer(user_text: str) -> Optional[str]:
    if not client:
        return None

    system_rules = (
        "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –∫–∞—Ñ–µ–¥—Ä—ã –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –ø—Ä–∞–≤–∞ (–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω). "
        "–°—Ç–∏–ª—å: –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ-–¥–µ–ª–æ–≤–æ–π, –∫—Ä–∞—Ç–∫–æ, –ø–æ —à–∞–≥–∞–º. "
        "–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–æ–º–µ—Ä–∞ —Å—Ç–∞—Ç–µ–π/–ø—Ä–∏–∫–∞–∑–æ–≤ –∏ —Ç–æ—á–Ω—ã–µ —Ä–µ–∫–≤–∏–∑–∏—Ç—ã, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç. "
        "–ï—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è —É—Ç–æ—á–Ω–µ–Ω–∏–µ ‚Äî –∑–∞–¥–∞–π 2-3 –∫–æ—Ä–æ—Ç–∫–∏—Ö —É—Ç–æ—á–Ω—è—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–∞. "
        "–í –∫–æ–Ω—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–∏ –∫–Ω–æ–ø–∫—É ¬´‚úâÔ∏è –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—é¬ª –¥–ª—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–≥–æ –∫–µ–π—Å–∞."
    )

    # Responses API (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π)
    resp = client.responses.create(
        model="gpt-4o-mini",
        input=[
            {"role": "system", "content": system_rules},
            {"role": "user", "content": user_text},
        ],
        # store –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω; –æ—Å—Ç–∞–≤–ª—è–µ–º false-–ª–æ–≥–∏–∫–æ–π (–±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
        store=False,
    )
    return (resp.output_text or "").strip() or None

async def openai_answer(user_text: str, timeout_s: int = 18) -> Optional[str]:
    if not client:
        return None
    loop = asyncio.get_event_loop()
    try:
        return await asyncio.wait_for(loop.run_in_executor(None, _openai_sync_answer, user_text), timeout=timeout_s)
    except Exception as e:
        logging.warning(f"OpenAI fallback failed: {e}")
        return None

# ---------- Aiogram ----------
if not TOKEN:
    raise RuntimeError("TELEGRAM_TOKEN is not set.")

bot = Bot(token=TOKEN)
dp = Dispatcher(bot)

@dp.message_handler(commands=["start"])
async def start(message: types.Message):
    text = (
        "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –Ø –±–æ—Ç –∫–∞—Ñ–µ–¥—Ä—ã –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –ø—Ä–∞–≤–∞.\n\n"
        "–Ø –ø–æ–º–æ–≥–∞—é —Å —Ç–∏–ø–æ–≤—ã–º–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏: –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –æ—à–∏–±–∫–∏, –∏–Ω—Ü–∏–¥–µ–Ω—Ç—ã, –∂–∞–ª–æ–±—ã, "
        "–∏–Ω—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–≥–ª–∞—Å–∏–µ, –≤—Ä–∞—á–µ–±–Ω–∞—è —Ç–∞–π–Ω–∞, –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å.\n\n"
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–¥–µ–ª –∫–Ω–æ–ø–∫–∞–º–∏ –Ω–∏–∂–µ –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ –≤–æ–ø—Ä–æ—Å —Ç–µ–∫—Å—Ç–æ–º."
    )
    await message.answer(text, reply_markup=menu)

@dp.message_handler(commands=["help", "menu"])
async def help_cmd(message: types.Message):
    await message.answer("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–¥–µ–ª –∫–Ω–æ–ø–∫–∞–º–∏ –∏–ª–∏ –Ω–∞–ø–∏—à–∏—Ç–µ –≤–æ–ø—Ä–æ—Å —Ç–µ–∫—Å—Ç–æ–º.", reply_markup=menu)

@dp.message_handler(lambda m: (m.text or "").strip() == "üìÑ –ù–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞")
async def law_base(message: types.Message):
    text = (
        "üìÑ –ù–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞ (–æ—Ä–∏–µ–Ω—Ç–∏—Ä—ã):\n"
        "‚Ä¢ –ö–æ–¥–µ–∫—Å –†–ö ¬´–û –∑–¥–æ—Ä–æ–≤—å–µ –Ω–∞—Ä–æ–¥–∞ –∏ —Å–∏—Å—Ç–µ–º–µ –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è¬ª\n"
        "‚Ä¢ –£–ö / –ö–æ–ê–ü / –ì–ö / –¢–ö –†–ö ‚Äî –ø–æ —Å–∏—Ç—É–∞—Ü–∏–∏\n"
        "‚Ä¢ –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Ä–µ–≥–ª–∞–º–µ–Ω—Ç—ã –º–µ–¥–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏ –ø—Ä–∏–∫–∞–∑—ã —É–ø–æ–ª–Ω–æ–º–æ—á–µ–Ω–Ω–æ–≥–æ –æ—Ä–≥–∞–Ω–∞\n\n"
        "–ï—Å–ª–∏ –Ω–∞–ø–∏—à–µ—Ç–µ —Ç–µ–º—É (–Ω–∞–ø—Ä–∏–º–µ—Ä, ¬´–≤—Ä–∞—á–µ–±–Ω–∞—è —Ç–∞–π–Ω–∞¬ª), —è –ø–æ–¥—Å–∫–∞–∂—É —Ç–∏–ø–æ–≤–æ–π –±–ª–æ–∫ –Ω–æ—Ä–º."
    )
    await message.answer(text, reply_markup=menu)

@dp.message_handler(lambda m: (m.text or "").strip() == "‚úâÔ∏è –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—é")
async def ask_teacher(message: types.Message):
    await message.answer(
        "–ù–∞–ø–∏—à–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º.\n"
        "–§–æ—Ä–º–∞—Ç: *–¢–µ–º–∞* ‚Üí *–°—É—Ç—å –≤–æ–ø—Ä–æ—Å–∞*.\n"
        "–ù–µ —É–∫–∞–∑—ã–≤–∞–π—Ç–µ –ª–∏—à–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.",
        parse_mode="Markdown",
        reply_markup=menu,
    )

@dp.message_handler(lambda m: (m.text or "").strip() == "üß™ –ú–∏–Ω–∏-—Ç–µ—Å—Ç—ã")
async def mini_tests(message: types.Message):
    USER_MODE[message.from_user.id] = "exam"
    await message.answer(
        "üß™ –≠–∫–∑–∞–º–µ–Ω–∞—Ü–∏–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º –≤–∫–ª—é—á—ë–Ω.\n\n"
        "–ü–∏—à–∏—Ç–µ —Ç–µ–º—É/–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞. –ß—Ç–æ–±—ã –≤—ã–π—Ç–∏ ‚Äî –Ω–∞–ø–∏—à–∏—Ç–µ: –≤—ã—Ö–æ–¥",
        reply_markup=menu,
    )

# –ö–Ω–æ–ø–∫–∞ —Ä–∞–∑–¥–µ–ª–∞: intro + def (–µ—Å–ª–∏ –µ—Å—Ç—å)
@dp.message_handler(lambda m: (m.text or "").strip() in SECTIONS)
async def handle_section_buttons(message: types.Message):
    key = (message.text or "").strip()

    # –¥–ª—è —Ç—Ä—ë—Ö —Å–ø–µ—Ü-–∫–Ω–æ–ø–æ–∫ —É–∂–µ –µ—Å—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ö—ç–Ω–¥–ª–µ—Ä—ã –≤—ã—à–µ
    if key in ("üìÑ –ù–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞", "‚úâÔ∏è –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—é", "üß™ –ú–∏–Ω–∏-—Ç–µ—Å—Ç—ã"):
        return

    intro = find_intro(key)
    definition = find_definition(key)

    parts = []
    if intro:
        parts.append((intro.get("answer") or "").strip())
    if definition and definition is not intro:
        parts.append((definition.get("answer") or "").strip())

    if parts:
        out = "\n\n".join([p for p in parts if p])
        out += f"\n\n{DISCLAIMER}"
        await message.answer(out, reply_markup=menu)
        return

    await message.answer(
        "–†–∞–∑–¥–µ–ª –æ—Ç–∫—Ä—ã—Ç. –ù–∞–ø–∏—à–∏—Ç–µ 1‚Äì2 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞ –ø–æ —Ç–µ–º–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä: ¬´–∂–∞–ª–æ–±–∞¬ª, ¬´–æ—Ç–∫–∞–∑–∞–ª–∏¬ª, ¬´—Ç–∞–π–Ω–∞¬ª).",
        reply_markup=menu
    )

# –ï–î–ò–ù–°–¢–í–ï–ù–ù–´–ô —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ö—ç–Ω–¥–ª–µ—Ä (—á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ —Ç–∏—à–∏–Ω—ã/–∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤)
@dp.message_handler(lambda m: m.text and (not m.text.startswith("/")) and ((m.text or "").strip() not in SECTIONS))
async def handle_text(message: types.Message):
    uid = message.from_user.id
    raw = (message.text or "").strip()

    # –≤—ã—Ö–æ–¥ –∏–∑ —ç–∫–∑–∞–º–µ–Ω-—Ä–µ–∂–∏–º–∞
    if USER_MODE.get(uid) == "exam" and raw.lower() in ("–≤—ã—Ö–æ–¥", "–≤—ã–π—Ç–∏", "exit"):
        USER_MODE.pop(uid, None)
        await message.answer("–≠–∫–∑–∞–º–µ–Ω–∞—Ü–∏–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º –≤—ã–∫–ª—é—á—ë–Ω. –ú–æ–∂–µ—Ç–µ –∑–∞–¥–∞–≤–∞—Ç—å –æ–±—ã—á–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã.", reply_markup=menu)
        return

    # 1) –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω exam-—Ä–µ–∂–∏–º ‚Äî —Å–Ω–∞—á–∞–ª–∞ EXAM
    if USER_MODE.get(uid) == "exam":
        exam_entry, exam_score = best_match(EXAM, raw, keyword_field="keywords")
        if exam_entry and exam_score >= 1.0:
            await message.answer(format_exam(exam_entry), reply_markup=menu)
            return
        await message.answer(
            "–ü–æ —ç—Ç–æ–º—É –∑–∞–ø—Ä–æ—Å—É —ç–∫–∑–∞–º–µ–Ω–∞—Ü–∏–æ–Ω–Ω–∞—è –∫–∞—Ä—Ç–æ—á–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.\n"
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø—Ä–æ—â–µ: ¬´–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å¬ª, ¬´–¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞—Ä–Ω–∞—è¬ª, ¬´—É–≥–æ–ª–æ–≤–Ω–∞—è¬ª.",
            reply_markup=menu,
        )
        return

    # 2) –æ–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º: —Å—Ä–∞–≤–Ω–∏–º FAQ –∏ EXAM –∏ –≤—ã–±–µ—Ä–µ–º –ª—É—á—à–µ–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
    faq_entry, faq_score = best_match(FAQ, raw, keyword_field="keywords")
    exam_entry, exam_score = best_match(EXAM, raw, keyword_field="keywords")

    # –ü–æ—Ä–æ–≥, —á—Ç–æ–±—ã –Ω–µ —Å—Ç—Ä–µ–ª—è—Ç—å –≤ –º—É—Å–æ—Ä
    faq_ok = faq_entry is not None and faq_score >= 0.9
    exam_ok = exam_entry is not None and exam_score >= 0.9

    # –ê–≤—Ç–æ–≤—ã–±–æ—Ä: –µ—Å–ª–∏ EXAM —è–≤–Ω–æ –ª—É—á—à–µ ‚Äî –æ—Ç–¥–∞–µ–º EXAM, –∏–Ω–∞—á–µ FAQ
    if faq_ok or exam_ok:
        if exam_ok and (exam_score > faq_score + 0.5):
            await message.answer(format_exam(exam_entry), reply_markup=menu)
            return

        # FAQ –æ—Ç–≤–µ—Ç + –¥–µ—Ñ–∏–Ω–∏—Ü–∏—è —Å–≤–µ—Ä—Ö—É, –µ—Å–ª–∏ –µ—Å—Ç—å
        section = (faq_entry.get("section") or "").strip()
        definition = find_definition(section) if section else None

        parts = []
        if definition and definition is not faq_entry:
            parts.append((definition.get("answer") or "").strip())

        parts.append((faq_entry.get("answer") or faq_entry.get("a") or "").strip())

        out = "\n\n".join([p for p in parts if p])
        law = (faq_entry.get("law") or "").strip()
        if law:
            out += f"\n\nüî∑ –ù–æ—Ä–º–∞—Ç–∏–≤–Ω–∞—è –±–∞–∑–∞: {law}"
        out += f"\n\n{DISCLAIMER}"

        await message.answer(out, reply_markup=menu)
        return

    # 3) –µ—Å–ª–∏ –±–∞–∑—ã –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –ø–æ–¥–∫–ª—é—á–∞–µ–º –º–µ–Ω—è (AI-fallback), –µ—Å–ª–∏ –∫–ª—é—á –∑–∞–¥–∞–Ω
    ai_text = await openai_answer(raw)
    if ai_text:
        out = ai_text.strip() + f"\n\n{DISCLAIMER}"
        await message.answer(out, reply_markup=menu)
        return

    # 4) —Å–æ–≤—Å–µ–º –Ω–∏—á–µ–≥–æ
    await message.answer(
        "–ù–µ –Ω–∞—à—ë–ª —Ç–æ—á–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.\n"
        "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø—Ä–æ—â–µ (1‚Äì2 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞) –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ ¬´‚úâÔ∏è –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—é¬ª.",
        reply_markup=menu,
    )

if __name__ == "__main__":
    executor.start_polling(dp, skip_updates=True)

